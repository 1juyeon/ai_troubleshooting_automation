import json
import os
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import pytz
import streamlit as st

class CloudDataStorage:
    """Streamlit Cloud í™˜ê²½ìš© ì„ì‹œ ë°ì´í„° ì €ì¥ì†Œ"""
    
    def __init__(self):
        self.data = {}
        self.timestamp = datetime.now().isoformat()
    
    def save(self, key: str, data: Any) -> bool:
        """ì„¸ì…˜ ìƒíƒœì— ë°ì´í„° ì €ì¥"""
        try:
            self.data[key] = {
                'data': data,
                'timestamp': datetime.now().isoformat()
            }
            return True
        except Exception as e:
            print(f"âŒ í´ë¼ìš°ë“œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def load(self, key: str) -> Any:
        """ì„¸ì…˜ ìƒíƒœì—ì„œ ë°ì´í„° ë¡œë“œ"""
        return self.data.get(key, {}).get('data', None)
    
    def get_all_keys(self) -> List[str]:
        """ì €ì¥ëœ ëª¨ë“  í‚¤ ë°˜í™˜"""
        return list(self.data.keys())

class MultiUserHistoryDB:
    def __init__(self, data_dir: str = "user_data"):
        """ë‹¤ì¤‘ ì‚¬ìš©ì ì´ë ¥ ì €ì¥ì†Œ ì´ˆê¸°í™”"""
        # Streamlit Cloud í™˜ê²½ ê°ì§€
        self.is_cloud = self._is_streamlit_cloud()
        
        # MongoDB í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” (ë‚˜ì¤‘ì— ì„¤ì •)
        self.mongo_handler = None
        
        if self.is_cloud:
            print("â˜ï¸ Streamlit Cloud í™˜ê²½ ê°ì§€ - í´ë¼ìš°ë“œ ì €ì¥ì†Œ í™•ì¸ ì¤‘...")
            self.storage_handler = self._get_cloud_storage()
        else:
            print("ğŸ’» ë¡œì»¬ í™˜ê²½ ê°ì§€ - íŒŒì¼ ì‹œìŠ¤í…œ ì‚¬ìš©")
            # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
            if not os.path.isabs(data_dir):
                self.data_dir = os.path.join(os.getcwd(), data_dir)
            else:
                self.data_dir = data_dir
            self._ensure_data_directory()
    
    def set_mongo_handler(self, mongo_handler):
        """MongoDB í•¸ë“¤ëŸ¬ ì„¤ì •"""
        self.mongo_handler = mongo_handler
        print("âœ… MongoDB í•¸ë“¤ëŸ¬ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _is_streamlit_cloud(self) -> bool:
        """Streamlit Cloud í™˜ê²½ì¸ì§€ í™•ì¸"""
        return os.getenv('STREAMLIT_SERVER_RUNNING') == 'true'
    
    def _get_cloud_storage(self):
        """í´ë¼ìš°ë“œ í™˜ê²½ìš© ì €ì¥ì†Œ ì„ íƒ"""
        try:
            # MongoDB ìš°ì„  ì‹œë„
            if "MONGODB_URI" in st.secrets:
                print("âœ… MongoDB Atlas ì—°ê²° ì‹œë„ ì¤‘...")
                from mongodb_handler import MongoDBHandler
                return MongoDBHandler()
            else:
                # MongoDB ì„¤ì •ì´ ì—†ìœ¼ë©´ ì„ì‹œ ì €ì¥ì†Œ ì‚¬ìš©
                print("âš ï¸ MongoDB ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. ì„ì‹œ ì €ì¥ì†Œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return CloudDataStorage()
        except Exception as e:
            print(f"âš ï¸ í´ë¼ìš°ë“œ ì €ì¥ì†Œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("ì„ì‹œ ì €ì¥ì†Œë¡œ í´ë°±í•©ë‹ˆë‹¤.")
            return CloudDataStorage()
    
    def _ensure_data_directory(self):
        """ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„± (ë¡œì»¬ í™˜ê²½ë§Œ)"""
        if self.is_cloud:
            return
            
        if not os.path.exists(self.data_dir):
            try:
                os.makedirs(self.data_dir)
                print(f"âœ… ì‚¬ìš©ì ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±: {self.data_dir}")
            except Exception as e:
                print(f"âš ï¸ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _get_safe_timestamp(self) -> str:
        """ì•ˆì „í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (í•œêµ­ ì‹œê°„ëŒ€, ì‹¤íŒ¨ ì‹œ UTC ì‚¬ìš©)"""
        try:
            return datetime.now(pytz.timezone('Asia/Seoul')).isoformat()
        except Exception as e:
            print(f"âš ï¸ í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì • ì‹¤íŒ¨, UTC ì‚¬ìš©: {e}")
            return datetime.now().isoformat()
    
    def _get_user_id(self, user_name: str, user_role: str) -> str:
        """ì‚¬ìš©ì ID ìƒì„± (ì´ë¦„ + ì—­í•  ê¸°ë°˜)"""
        user_string = f"{user_name}_{user_role}"
        return hashlib.md5(user_string.encode()).hexdigest()[:8]
    
    def _get_user_history_file(self, user_id: str) -> str:
        """ì‚¬ìš©ìë³„ ì´ë ¥ íŒŒì¼ ê²½ë¡œ (ë¡œì»¬ í™˜ê²½ë§Œ)"""
        if self.is_cloud:
            return f"cloud_history_{user_id}"
        return os.path.join(self.data_dir, f"history_{user_id}.json")
    
    def _get_global_history_file(self) -> str:
        """ì „ì²´ ì´ë ¥ íŒŒì¼ ê²½ë¡œ (ë¡œì»¬ í™˜ê²½ë§Œ)"""
        if self.is_cloud:
            return "cloud_global_history"
        return os.path.join(self.data_dir, "global_history.json")
    
    def _ensure_history_file(self, file_path: str):
        """ì´ë ¥ íŒŒì¼ ìƒì„± (ë¡œì»¬ í™˜ê²½ë§Œ)"""
        if self.is_cloud:
            return
            
        if not os.path.exists(file_path):
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump([], f, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"âš ï¸ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _load_history(self, file_path: str) -> List[Dict]:
        """ì´ë ¥ ë°ì´í„° ë¡œë“œ"""
        if self.is_cloud:
            # í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œëŠ” ì„¸ì…˜ ìƒíƒœì—ì„œ ë¡œë“œ
            cloud_key = file_path
            data = self.cloud_storage.load(cloud_key)
            return data if data else []
        
        try:
            self._ensure_history_file(file_path)
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ ì´ë ¥ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def _save_history(self, history_data: List[Dict], file_path: str) -> bool:
        """ì´ë ¥ ë°ì´í„° ì €ì¥"""
        if self.is_cloud:
            # í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œëŠ” ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            cloud_key = file_path
            return self.cloud_storage.save(cloud_key, history_data)
        
        try:
            # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # ì„ì‹œ íŒŒì¼ì— ë¨¼ì € ì €ì¥
            temp_file = file_path + '.tmp'
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(history_data, f, ensure_ascii=False, indent=2)
            
            # ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ë©´ ì›ë³¸ íŒŒì¼ë¡œ ì´ë™
            if os.path.exists(file_path):
                backup_file = file_path + '.backup'
                try:
                    os.rename(file_path, backup_file)
                except Exception as e:
                    print(f"âš ï¸ ë°±ì—… íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            
            os.rename(temp_file, file_path)
            return True
            
        except PermissionError as e:
            print(f"âŒ íŒŒì¼ ê¶Œí•œ ì˜¤ë¥˜: {e}")
            print(f"íŒŒì¼ ê²½ë¡œ: {file_path}")
            return False
        except OSError as e:
            print(f"âŒ íŒŒì¼ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            print(f"íŒŒì¼ ê²½ë¡œ: {file_path}")
            return False
        except Exception as e:
            print(f"âŒ ì´ë ¥ ì €ì¥ ì‹¤íŒ¨: {e}")
            print(f"íŒŒì¼ ê²½ë¡œ: {file_path}")
            return False
    
    def save_analysis(self, analysis_result: Dict, inquiry_data: Dict):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥ (ì‚¬ìš©ìë³„ + ì „ì²´)"""
        try:
            # ì‚¬ìš©ì ID ìƒì„±
            user_name = inquiry_data.get('user_name', 'Unknown')
            user_role = inquiry_data.get('user_role', 'Unknown')
            user_id = self._get_user_id(user_name, user_role)
            
            # ì‚¬ìš©ìë³„ ì´ë ¥ íŒŒì¼
            user_history_file = self._get_user_history_file(user_id)
            user_history = self._load_history(user_history_file)
            
            # ì „ì²´ ì´ë ¥ íŒŒì¼
            global_history_file = self._get_global_history_file()
            global_history = self._load_history(global_history_file)
            
            # ìƒˆë¡œìš´ ë¶„ì„ ê²°ê³¼ ìƒì„±
            new_entry = {
                'id': len(user_history) + 1,
                'user_id': user_id,
                'user_name': user_name,
                'user_role': user_role,
                'timestamp': inquiry_data.get('timestamp', self._get_safe_timestamp()),
                'customer_name': inquiry_data.get('customer_name', ''),
                'customer_contact': inquiry_data.get('customer_contact', ''),
                'customer_manager': inquiry_data.get('customer_manager', ''),
                'inquiry_content': inquiry_data.get('inquiry_content', ''),
                'issue_type': analysis_result.get('issue_type', ''),
                'classification_method': analysis_result.get('classification', {}).get('method', ''),
                'confidence': analysis_result.get('classification', {}).get('confidence', ''),
                'response_type': analysis_result.get('gemini_result', {}).get('parsed_response', {}).get('response_type', ''),
                'summary': analysis_result.get('gemini_result', {}).get('parsed_response', {}).get('summary', ''),
                'action_flow': analysis_result.get('gemini_result', {}).get('parsed_response', {}).get('action_flow', ''),
                'email_draft': analysis_result.get('gemini_result', {}).get('parsed_response', {}).get('email_draft', ''),
                'system_version': inquiry_data.get('system_version', ''),
                'browser_info': inquiry_data.get('browser_info', ''),
                'os_info': inquiry_data.get('os_info', ''),
                'error_code': inquiry_data.get('error_code', ''),
                'priority': inquiry_data.get('priority', ''),
                'contract_type': inquiry_data.get('contract_type', ''),
                'full_analysis_result': analysis_result
            }
            
            # ì‚¬ìš©ìë³„ ì´ë ¥ì— ì¶”ê°€
            user_history.append(new_entry)
            
            # ì „ì²´ ì´ë ¥ì— ì¶”ê°€ (ì‚¬ìš©ì ì •ë³´ í¬í•¨)
            global_entry = new_entry.copy()
            global_entry['global_id'] = len(global_history) + 1
            global_history.append(global_entry)
            
            # ì €ì¥
            user_saved = self._save_history(user_history, user_history_file)
            global_saved = self._save_history(global_history, global_history_file)
            
            if user_saved and global_saved:
                print(f"âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ (ì‚¬ìš©ì: {user_name}, ID: {user_id})")
                return {
                    "success": True, 
                    "database": "multi_user_json",
                    "id": new_entry['id'],  # ë¶„ì„ ê²°ê³¼ ID ì¶”ê°€
                    "user_id": user_id,
                    "user_name": user_name
                }
            else:
                return {"success": False, "error": "ì €ì¥ ì‹¤íŒ¨"}
                
        except Exception as e:
            print(f"âŒ ë‹¤ì¤‘ ì‚¬ìš©ì ì €ì¥ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def get_user_history(self, user_name: str, user_role: str, 
                        limit: int = 50, offset: int = 0,
                        issue_type: str = None, date_from: str = None, 
                        date_to: str = None, keyword: str = None):
        """ì‚¬ìš©ìë³„ ì´ë ¥ ì¡°íšŒ"""
        try:
            user_id = self._get_user_id(user_name, user_role)
            user_history_file = self._get_user_history_file(user_id)
            history = self._load_history(user_history_file)
            
            # í•„í„°ë§
            filtered_history = self._filter_history(history, issue_type, date_from, date_to, keyword)
            
            # í˜ì´ì§•
            total_count = len(filtered_history)
            paginated_history = filtered_history[offset:offset + limit]
            
            return {
                "success": True,
                "data": paginated_history,
                "total_count": total_count,
                "user_id": user_id,
                "user_name": user_name
            }
            
        except Exception as e:
            print(f"âŒ ì‚¬ìš©ì ì´ë ¥ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def get_global_history(self, limit: int = 50, offset: int = 0,
                          issue_type: str = None, date_from: str = None, 
                          date_to: str = None, keyword: str = None,
                          user_name: str = None):
        """ì „ì²´ ì´ë ¥ ì¡°íšŒ"""
        try:
            global_history_file = self._get_global_history_file()
            history = self._load_history(global_history_file)
            
            # í•„í„°ë§
            filtered_history = self._filter_history(history, issue_type, date_from, date_to, keyword, user_name)
            
            # í˜ì´ì§•
            total_count = len(filtered_history)
            paginated_history = filtered_history[offset:offset + limit]
            
            return {
                "success": True,
                "data": paginated_history,
                "total_count": total_count
            }
            
        except Exception as e:
            print(f"âŒ ì „ì²´ ì´ë ¥ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def _filter_history(self, history: List[Dict], issue_type: str = None, 
                       date_from: str = None, date_to: str = None, 
                       keyword: str = None, user_name: str = None) -> List[Dict]:
        """ì´ë ¥ í•„í„°ë§"""
        filtered_history = []
        
        for entry in history:
            # ë¬¸ì œ ìœ í˜• í•„í„°
            if issue_type and entry.get('issue_type') != issue_type:
                continue
            
            # ì‚¬ìš©ì í•„í„°
            if user_name and entry.get('user_name') != user_name:
                continue
            
            # ë‚ ì§œ í•„í„°
            if date_from and entry.get('timestamp', '') < date_from:
                continue
            if date_to and entry.get('timestamp', '') > date_to:
                continue
            
            # í‚¤ì›Œë“œ í•„í„°
            if keyword:
                search_text = f"{entry.get('inquiry_content', '')} {entry.get('customer_name', '')} {entry.get('issue_type', '')}"
                if keyword.lower() not in search_text.lower():
                    continue
            
            filtered_history.append(entry)
        
        # ìµœì‹ ìˆœ ì •ë ¬
        filtered_history.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        return filtered_history
    
    def get_statistics(self, user_name: str = None, user_role: str = None):
        """í†µê³„ ì¡°íšŒ"""
        try:
            if user_name and user_role:
                # ì‚¬ìš©ìë³„ í†µê³„
                user_id = self._get_user_id(user_name, user_role)
                user_history_file = self._get_user_history_file(user_id)
                history = self._load_history(user_history_file)
                
                issue_types = list(set([entry.get('issue_type', '') for entry in history if entry.get('issue_type')]))
                response_types = list(set([entry.get('response_type', '') for entry in history if entry.get('response_type')]))
                
                return {
                    "success": True,
                    "total_analyses": len(history),
                    "issue_types": issue_types,
                    "response_types": response_types,
                    "user_id": user_id,
                    "user_name": user_name,
                    "user_role": user_role
                }
            else:
                # ì „ì²´ í†µê³„
                global_history_file = self._get_global_history_file()
                history = self._load_history(global_history_file)
                
                # ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ (user_nameê³¼ user_roleì´ ëª¨ë‘ ìˆëŠ” ê²½ìš°ë§Œ)
                users = []
                for entry in history:
                    user_name_val = entry.get('user_name', '')
                    user_role_val = entry.get('user_role', '')
                    if user_name_val and user_role_val:
                        user_key = f"{user_name_val}_{user_role_val}"
                        if user_key not in users:
                            users.append(user_key)
                
                # ë¬¸ì œ ìœ í˜• ì¶”ì¶œ (issue_typeì´ ìˆëŠ” ê²½ìš°ë§Œ)
                issue_types = []
                for entry in history:
                    issue_type = entry.get('issue_type', '')
                    if issue_type and issue_type not in issue_types:
                        issue_types.append(issue_type)
                
                # ì‘ë‹µ ìœ í˜• ì¶”ì¶œ (response_typeì´ ìˆëŠ” ê²½ìš°ë§Œ)
                response_types = []
                for entry in history:
                    response_type = entry.get('response_type', '')
                    if response_type and response_type not in response_types:
                        response_types.append(response_type)
                
                # full_analysis_resultì—ì„œ response_type ì¶”ì¶œ ì‹œë„
                for entry in history:
                    full_result = entry.get('full_analysis_result', {})
                    if full_result:
                        gemini_result = full_result.get('gemini_result', {})
                        if gemini_result:
                            parsed_response = gemini_result.get('parsed_response', {})
                            if parsed_response:
                                response_type = parsed_response.get('response_type', '')
                                if response_type and response_type not in response_types:
                                    response_types.append(response_type)
                
                return {
                    "success": True,
                    "total_analyses": len(history),
                    "total_users": len(users),
                    "issue_types": issue_types,
                    "response_types": response_types
                }
                
        except Exception as e:
            print(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def clear_user_history(self, user_name: str, user_role: str):
        """ì‚¬ìš©ìë³„ ì´ë ¥ ì‚­ì œ"""
        try:
            user_id = self._get_user_id(user_name, user_role)
            user_history_file = self._get_user_history_file(user_id)
            
            if self.is_cloud:
                # í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œëŠ” ì„¸ì…˜ ìƒíƒœì—ì„œ ì‚­ì œ
                cloud_key = user_history_file
                self.cloud_storage.data.pop(cloud_key, None)
                print(f"âœ… ì‚¬ìš©ì ì´ë ¥ ì‚­ì œ ì™„ë£Œ (í´ë¼ìš°ë“œ): {user_name} ({user_id})")
                return {"success": True, "user_id": user_id}
            else:
                if os.path.exists(user_history_file):
                    os.remove(user_history_file)
                    print(f"âœ… ì‚¬ìš©ì ì´ë ¥ ì‚­ì œ ì™„ë£Œ: {user_name} ({user_id})")
                    return {"success": True, "user_id": user_id}
                else:
                    return {"success": False, "error": "ì‚¬ìš©ì ì´ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}
                
        except Exception as e:
            print(f"âŒ ì‚¬ìš©ì ì´ë ¥ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def get_analysis_by_customer_and_date(self, customer_name: str, inquiry_date: str):
        """ê³ ê°ì‚¬ëª…ê³¼ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        try:
            # ì „ì²´ ì´ë ¥ì—ì„œ í•´ë‹¹ ê³ ê°ì˜ ë¬¸ì˜ ì°¾ê¸°
            global_history_file = self._get_global_history_file()
            history = self._load_history(global_history_file)
            
            # ê³ ê°ì‚¬ëª…ê³¼ ë‚ ì§œë¡œ í•„í„°ë§
            matching_entries = []
            for entry in history:
                entry_customer = entry.get('customer_name', '')
                entry_timestamp = entry.get('timestamp', '')
                
                # ê³ ê°ì‚¬ëª… ë§¤ì¹­
                if customer_name and entry_customer != customer_name:
                    continue
                
                # ë‚ ì§œ ë§¤ì¹­ (YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë¹„êµ)
                if inquiry_date and entry_timestamp:
                    entry_date = entry_timestamp.split('T')[0] if 'T' in entry_timestamp else entry_timestamp.split(' ')[0]
                    if entry_date != inquiry_date:
                        continue
                
                matching_entries.append(entry)
            
            if matching_entries:
                # ê°€ì¥ ìµœê·¼ í•­ëª© ë°˜í™˜
                latest_entry = max(matching_entries, key=lambda x: x.get('timestamp', ''))
                
                # full_analysis_resultì—ì„œ ì‹¤ì œ AI ë¶„ì„ ë°ì´í„° ì¶”ì¶œ
                full_result = latest_entry.get('full_analysis_result', {})
                
                # ë¶„ì„ ê²°ê³¼ ë°ì´í„° êµ¬ì„±
                analysis_data = {
                    'issue_type': full_result.get('issue_type', latest_entry.get('issue_type', '')),
                    'best_scenario': full_result.get('best_scenario', {}),
                    'gemini_result': full_result.get('gemini_result', {}),
                    'classification': full_result.get('classification', {}),
                    'customer_name': latest_entry.get('customer_name', ''),
                    'timestamp': latest_entry.get('timestamp', ''),
                    'inquiry_content': latest_entry.get('inquiry_content', ''),
                    'priority': latest_entry.get('priority', ''),
                    'contract_type': latest_entry.get('contract_type', '')
                }
                
                return {
                    "success": True,
                    "data": analysis_data
                }
            else:
                return {
                    "success": False,
                    "error": "í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }
                
        except Exception as e:
            print(f"âŒ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def clear_all_history(self):
        """ì „ì²´ ì´ë ¥ ì‚­ì œ"""
        try:
            if self.is_cloud:
                # í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œëŠ” ì„¸ì…˜ ìƒíƒœ ë°ì´í„° ëª¨ë‘ ì‚­ì œ
                self.cloud_storage.data.clear()
                print("âœ… ì „ì²´ ì´ë ¥ ì‚­ì œ ì™„ë£Œ (í´ë¼ìš°ë“œ)")
                return {"success": True}
            else:
                # ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” íŒŒì¼ë“¤ ì‚­ì œ
                for filename in os.listdir(self.data_dir):
                    if filename.startswith("history_") and filename.endswith(".json"):
                        file_path = os.path.join(self.data_dir, filename)
                        os.remove(file_path)
                
                # ì „ì²´ ì´ë ¥ íŒŒì¼ ì‚­ì œ
                global_history_file = self._get_global_history_file()
                if os.path.exists(global_history_file):
                    os.remove(global_history_file)
                
                print("âœ… ì „ì²´ ì´ë ¥ ì‚­ì œ ì™„ë£Œ")
                return {"success": True}
            
        except Exception as e:
            print(f"âŒ ì „ì²´ ì´ë ¥ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def save_feedback(self, analysis_id, feedback_type: str, user_name: str = "", user_role: str = ""):
        """AI ì‘ë‹µì— ëŒ€í•œ í”¼ë“œë°± ì €ì¥ (MongoDB ìš°ì„ )"""
        try:
            print(f"ğŸ” í”¼ë“œë°± ì €ì¥ ì‹œë„ - Analysis ID: {analysis_id}, Type: {type(analysis_id)}")
            print(f"ğŸ” í”¼ë“œë°± íƒ€ì…: {feedback_type}, ì‚¬ìš©ì: {user_name}, ì—­í• : {user_role}")
            
            # MongoDB ì—°ê²° ìƒíƒœ í™•ì¸ ë° ìš°ì„  ì‚¬ìš©
            if hasattr(self, 'mongo_handler') and self.mongo_handler and self.mongo_handler.is_connected():
                print("ğŸ“Š MongoDBë¥¼ í†µí•œ í”¼ë“œë°± ì €ì¥ ì‹œë„")
                result = self.mongo_handler.save_feedback(analysis_id, feedback_type, user_name, user_role)
                print(f"ğŸ“Š MongoDB í”¼ë“œë°± ì €ì¥ ê²°ê³¼: {result}")
                return result
            
            # MongoDB ì‚¬ìš© ë¶ˆê°€ì‹œ ë¡œì»¬/í´ë¼ìš°ë“œ ì €ì¥ì†Œ ì‚¬ìš©
            print("ğŸ“Š ë¡œì»¬/í´ë¼ìš°ë“œ ì €ì¥ì†Œë¥¼ í†µí•œ í”¼ë“œë°± ì €ì¥ ì‹œë„")
            feedback_file = self._get_feedback_file()
            feedback_data = self._load_history(feedback_file)
            
            new_feedback = {
                'analysis_id': analysis_id,
                'feedback_type': feedback_type,
                'user_name': user_name,
                'user_role': user_role,
                'timestamp': self._get_safe_timestamp()
            }
            
            feedback_data.append(new_feedback)
            
            if self._save_history(feedback_data, feedback_file):
                print("âœ… ë¡œì»¬/í´ë¼ìš°ë“œ í”¼ë“œë°± ì €ì¥ ì„±ê³µ")
                return {"success": True}
            else:
                print("âŒ ë¡œì»¬/í´ë¼ìš°ë“œ í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨")
                return {"success": False, "error": "í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨"}
                
        except Exception as e:
            print(f"âŒ í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"success": False, "error": str(e)}
    
    def get_liked_responses(self, issue_type: str = None, limit: int = 3):
        """ì¢‹ì•„ìš”ë¥¼ ë°›ì€ ì‘ë‹µë“¤ ì¡°íšŒ (AI í•™ìŠµìš©, MongoDB ìš°ì„ )"""
        try:
            # MongoDB ì—°ê²° ìƒíƒœ í™•ì¸ ë° ìš°ì„  ì‚¬ìš©
            if hasattr(self, 'mongo_handler') and self.mongo_handler and self.mongo_handler.is_connected():
                return self.mongo_handler.get_liked_responses(issue_type, limit)
            
            # MongoDB ì‚¬ìš© ë¶ˆê°€ì‹œ ë¡œì»¬/í´ë¼ìš°ë“œ ì €ì¥ì†Œ ì‚¬ìš©
            feedback_file = self._get_feedback_file()
            feedback_data = self._load_history(feedback_file)
            
            # ì¢‹ì•„ìš”ë¥¼ ë°›ì€ ë¶„ì„ IDë“¤ ì¶”ì¶œ
            liked_ids = [f['analysis_id'] for f in feedback_data if f.get('feedback_type') == 'like']
            
            if not liked_ids:
                return []
            
            # í•´ë‹¹ ë¶„ì„ ê²°ê³¼ë“¤ ì¡°íšŒ
            global_history_file = self._get_global_history_file()
            global_history = self._load_history(global_history_file)
            
            liked_responses = []
            for entry in global_history:
                if entry.get('id') in liked_ids:
                    if not issue_type or entry.get('issue_type') == issue_type:
                        liked_responses.append({
                            'summary': entry.get('summary', ''),
                            'action_flow': entry.get('action_flow', ''),
                            'email_draft': entry.get('email_draft', '')
                        })
            
            return liked_responses[:limit]
            
        except Exception as e:
            print(f"âŒ ì¢‹ì•„ìš” ì‘ë‹µ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def _get_feedback_file(self):
        """í”¼ë“œë°± íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
        if self.is_cloud:
            return "feedback_data"
        else:
            return os.path.join(self.data_dir, "feedback_data.json")